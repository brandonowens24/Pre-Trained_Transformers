# Pre-Trained_Transformers

## About
* Jupyter notebook completed in **Google Colab**
* Imported **"sms_spam"** dataset from Huggingface.com
* **Fine-tuned** pre-trained transformer models
    * **BERT**
    * **ELECTRA**
* **Prompt-engineered** two **zero-shot** classfication models to see if they could predict "spam" or "ham"
    * **Bart**
    * **SELECTRA**
* Created **baseline** models to compare fine-tuned pre-trained transformers to
    * **Random-Guess Model**
    * **Target-Guess Model**
    * **BOW Logistic Regression**